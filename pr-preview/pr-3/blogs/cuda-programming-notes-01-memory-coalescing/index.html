<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>CUDA Programming Notes | 01: Memory Coalescing | 秋水·JamesNULLiu</title><meta name=keywords content="memory coalescing"><meta name=description content="Introduction to memory coalescing with Nsight Compute."><meta name=author content="jamesnulliu"><link rel=canonical href=https://jamesnulliu.github.io/blogs/cuda-programming-notes-01-memory-coalescing/><link crossorigin=anonymous href=/assets/css/stylesheet.62cb9c488bb33c0e9a9d3c29b7f4259cbb0db25aaa19ba672188203d3d5bcaf9.css integrity="sha256-YsucSIuzPA6anTwpt/QlnLsNslqqGbpnIYggPT1byvk=" rel="preload stylesheet" as=style><link rel=icon href=https://jamesnulliu.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://jamesnulliu.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://jamesnulliu.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://jamesnulliu.github.io/apple-touch-icon.png><link rel=mask-icon href=https://jamesnulliu.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://jamesnulliu.github.io/blogs/cuda-programming-notes-01-memory-coalescing/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]]}}</script><meta property="og:url" content="https://jamesnulliu.github.io/blogs/cuda-programming-notes-01-memory-coalescing/"><meta property="og:site_name" content="秋水·JamesNULLiu"><meta property="og:title" content="CUDA Programming Notes | 01: Memory Coalescing"><meta property="og:description" content="Introduction to memory coalescing with Nsight Compute."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2025-03-16T01:39:00+08:00"><meta property="article:modified_time" content="2025-09-12T21:45:48+00:00"><meta property="article:tag" content="Cuda"><meta property="article:tag" content="Optimization"><meta name=twitter:card content="summary"><meta name=twitter:title content="CUDA Programming Notes | 01: Memory Coalescing"><meta name=twitter:description content="Introduction to memory coalescing with Nsight Compute."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://jamesnulliu.github.io/blogs/"},{"@type":"ListItem","position":2,"name":"CUDA Programming Notes | 01: Memory Coalescing","item":"https://jamesnulliu.github.io/blogs/cuda-programming-notes-01-memory-coalescing/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"CUDA Programming Notes | 01: Memory Coalescing","name":"CUDA Programming Notes | 01: Memory Coalescing","description":"Introduction to memory coalescing with Nsight Compute.","keywords":["memory coalescing"],"articleBody":"1. Introduction to Memory Coalescing 1.1. Dynamic Random Access Memories (DRAMs) Accessing data in the global memory is critical to the performance of a CUDA application.\nIn addition to tiling techniques utilizing shared memories, we discuss memory coalescing techniques to move data efficiently from global memory into shared memory and registers.\nGlobal memory is implemented with dynamic random access memories (DRAMs). Reading one DRAM is a very slow process.\nModern DRAMs use a parallel process: Each time a location is accessed, many consecutive locations that includes the requested location are accessed.\nIf an application uses data from consecutive locations before moving on to other locations, the DRAMs work close to the advertised peak global memory bandwidth.\n1.2. Memory Coalescing Recall that all threads in a warp execute the same instruction.\nWhen all threads in a warp execute a load instruction, the hardware detects whether the threads access consecutive memory locations.\nThe most favorable global memory access is achieved when the same instruction for all threads in a warp accesses global memory locations.\nIn this favorable case, the hardware coalesces all memory accesses into a consolidated access to consecutive DRAM locations.\nDefinition: Memory Coalescing\nIf, in a warp, thread $0$ accesses location $n$, thread $1$ accesses location $n + 1$, … thread $31$ accesses location $n + 31$, then all these accesses are coalesced, that is: combined into one single access.\nThe CUDA C Best Practices Guide gives a high priority recommendation to coalesced access to global memory.\n2. Example: Vector Addition 2.1. Coalesced Access Coalesced Memory Access means that each thread in a warp accesses consecutive memory locations so that the hardware can combine all these accesses into one single access. By doing so, fewer wasted data are transferred and the memory bandwidth is fully utilized.\nClick to See Example Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 __global__ void vecAddKernel(const fp32_t* a, const fp32_t* b, fp32_t* c, int32_t n) { int gtid = threadIdx.x + blockDim.x * blockIdx.x; if (gtid \u003c n) { // [DRAM] 2 load, 1 store, 3 inst c[gtid] = a[gtid] + b[gtid]; } } void launchVecAdd(const fp32_t* d_A, const fp32_t* d_B, fp32_t* d_C, size_t n) { dim3 blockSize = {std::min\u003cuint32_t\u003e(n, 1024), 1, 1}; dim3 gridSize = {ceilDiv\u003cuint32_t\u003e(n, blockSize.x), 1, 1}; vecAddKernel\u003c\u003c\u003cgridSize, blockSize\u003e\u003e\u003e(d_A, d_B, d_C, int32_t(n)); } Note that in NVIDIA GPUs:\nWARP is the smallest unit of execution, which contains 32 threads. SECTOR is the smallest unit of data that can be accessed from global memory, which is exactly 32 bytes. In the example above, all threads in a warp access consecutive memory locations both for a, b, and c, and for each $32 * 4 / 32 = 4$ sectors, only ONE instruction to a warp is needed to access the data. This is so-called coalesced memory access.\nCoalesced Memory Access. There are 2N loads operations and 1N store operations in the kernel, which in all are 2N/32 load instructions and 1N/32 store instructions for warps (each warp executes 1 instruction). Since the access to memroy is coalesced, one instruction will transfer 4 sectors of data. There are no any wasted data. Another example of coalesced memory access is shown below:\nClick to See Example Code 1 2 3 4 5 6 7 8 9 10 __global__ void vecAddKernelv1(const fp32_t* a, const fp32_t* b, fp32_t* c, int32_t n) { int gtid = threadIdx.x + blockDim.x * blockIdx.x; gtid = gtid % 2 == 0 ? gtid + 1 : gtid - 1; if (gtid \u003c n) { // [DRAM] 2 load, 1 store, 3 inst c[gtid] = a[gtid] + b[gtid]; } } Crompared to the previous example, each 2 threads exchange their access positions. However, the access to memory is still coalesced.\nAnother Example of Coalesced Memory Access. 1 intruction will transfer 4 sectors of data. There are no any wasted data. 2.2. Non-Coalesced Access Non-Coalesced Memory Access means that some thread in a warp accesses non-consecutive memory locations so that the hardware cannot combine all these accesses into one single access. By doing so, more wasted data are transferred and the memory bandwidth is not fully utilized.\nSee the example code below. Originally, 32 threads in a warp would access 32 consecutive fp32 elements. However, I make the first thread in each warp access the 33th fp32 element (which should be accessed by the next warp), making an intented non-coalesced access.\nClick to See Example Code 1 2 3 4 5 6 7 8 9 10 11 12 __global__ void vecAddKernelv1(const fp32_t* a, const fp32_t* b, fp32_t* c, int32_t n) { int gtid = threadIdx.x + blockDim.x * blockIdx.x; if (gtid % warpSize == 0) { gtid = (gtid + warpSize) % (ceilDiv(n, warpSize) * warpSize); } if (gtid \u003c n) { // [DRAM] 2 load, 1 store, 3 inst c[gtid] = a[gtid] + b[gtid]; } } The memory access pattern is shown in the figure below. Campare to the previous examples, you can see that despite the total number of load/store instructions is the same (2N/32 load instructions and 1N/32 store instructions), for each warp, 5 sectors of data are now being transferred per instruction. From the perspective of hardware, more data are being transferred than needed.\nNon-Coalesced Memory Access. There are 2N/32 load instructions and 1N/32 store instructions for warps. But one instruction will transfer 5 sectors of data, as shown in the first warp with 5 orange sectors. In Nsight Compute, you can see the performance analysis in the “Memory Workload Analysis” section. Optimization suggestions are provided for reducing wasted data transfer.\nPerformance analysis of non-coalesced memory access using Nsight Compute. References Programming Massively Parallel Processors: A Hands-on Approach, 4th Edition 【CUDA调优指南】合并访存 Memory Coalescing Techniques ","wordCount":"969","inLanguage":"en","datePublished":"2025-03-16T01:39:00+08:00","dateModified":"2025-09-12T21:45:48Z","author":[{"@type":"Person","name":"jamesnulliu"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://jamesnulliu.github.io/blogs/cuda-programming-notes-01-memory-coalescing/"},"publisher":{"@type":"Organization","name":"秋水·JamesNULLiu","logo":{"@type":"ImageObject","url":"https://jamesnulliu.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://jamesnulliu.github.io/ accesskey=h title="秋水·JamesNULLiu (Alt + H)">秋水·JamesNULLiu</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://jamesnulliu.github.io/zh/ title=简体中文 aria-label=简体中文>简体中文</a></li></ul></div></div><ul id=menu><li><a href=https://jamesnulliu.github.io/ title=Home><span>Home</span></a></li><li><a href=https://jamesnulliu.github.io/about_me/ title="About Me"><span>About Me</span></a></li><li><a href=https://jamesnulliu.github.io/blogs/ title=Blogs><span>Blogs</span></a></li><li><a href=https://jamesnulliu.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://jamesnulliu.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://jamesnulliu.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://jamesnulliu.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://jamesnulliu.github.io/friends/ title=Friends><span>Friends</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://jamesnulliu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://jamesnulliu.github.io/blogs/>Blogs</a></div><h1 class="post-title entry-hint-parent">CUDA Programming Notes | 01: Memory Coalescing</h1><div class=post-description>Introduction to memory coalescing with Nsight Compute.</div><div class=post-meta><span title='2025-03-16 01:39:00 +0800 +0800'>Mar-16-2025</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;969 words&nbsp;·&nbsp;jamesnulliu</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-introduction-to-memory-coalescing aria-label="1. Introduction to Memory Coalescing">1. Introduction to Memory Coalescing</a><ul><li><a href=#11-dynamic-random-access-memories-drams aria-label="1.1. Dynamic Random Access Memories (DRAMs)">1.1. Dynamic Random Access Memories (DRAMs)</a></li><li><a href=#12-memory-coalescing aria-label="1.2. Memory Coalescing">1.2. Memory Coalescing</a></li></ul></li><li><a href=#2-example-vector-addition aria-label="2. Example: Vector Addition">2. Example: Vector Addition</a><ul><li><a href=#21-coalesced-access aria-label="2.1. Coalesced Access">2.1. Coalesced Access</a></li><li><a href=#22-non-coalesced-access aria-label="2.2. Non-Coalesced Access">2.2. Non-Coalesced Access</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{let e=null;const t=window.innerHeight+window.pageYOffset>=document.body.offsetHeight-100;if(t)e=elements[elements.length-1];else{let t=null,n=1/0;elements.forEach(e=>{const s=getOffsetTop(e)-window.pageYOffset;if(s<=window.innerHeight*.3){const o=Math.abs(s);o<n&&(n=o,t=e)}}),e=t||elements[0]}if(e&&e!==activeElement){if(activeElement){const t=encodeURI(activeElement.getAttribute("id")).toLowerCase(),e=document.querySelector(`.inner ul li a[href="#${t}"]`);e&&e.classList.remove("active")}activeElement=e;const n=encodeURI(activeElement.getAttribute("id")).toLowerCase(),t=document.querySelector(`.inner ul li a[href="#${n}"]`);t&&(t.classList.add("active"),document.getElementById("toc-container").classList.contains("wide")&&scrollTocToActiveItem(t))}},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}function scrollTocToActiveItem(e){const t=document.querySelector(".toc .inner");if(!t||!e)return;const n=t.getBoundingClientRect(),s=e.getBoundingClientRect(),o=n.height/2,i=s.top-n.top+t.scrollTop,a=i-o;t.scrollTo({top:Math.max(0,a),behavior:"smooth"})}</script><div class=post-content><h2 id=1-introduction-to-memory-coalescing>1. Introduction to Memory Coalescing<a hidden class=anchor aria-hidden=true href=#1-introduction-to-memory-coalescing>#</a></h2><h3 id=11-dynamic-random-access-memories-drams>1.1. Dynamic Random Access Memories (DRAMs)<a hidden class=anchor aria-hidden=true href=#11-dynamic-random-access-memories-drams>#</a></h3><p>Accessing data in the global memory is critical to the performance of a CUDA application.</p><p>In addition to tiling techniques utilizing shared memories, we discuss memory coalescing techniques to move data efficiently <strong>from global memory into shared memory and registers</strong>.</p><p>Global memory is implemented with dynamic random access memories (DRAMs). Reading one DRAM is a very slow process.</p><p>Modern DRAMs use a parallel process: <strong>Each time a location is accessed, many consecutive locations that includes the requested location are accessed</strong>.</p><p>If an application uses data from consecutive locations before moving on to other locations, the DRAMs work close to the advertised peak global memory bandwidth.</p><h3 id=12-memory-coalescing>1.2. Memory Coalescing<a hidden class=anchor aria-hidden=true href=#12-memory-coalescing>#</a></h3><p>Recall that <strong>all threads in a warp execute the same instruction</strong>.</p><p>When all threads in a warp execute a load instruction, the hardware detects whether the threads access consecutive memory locations.</p><p>The most favorable global memory access is achieved when the same instruction for all threads in a warp accesses global memory locations.</p><p>In this favorable case, the hardware coalesces all memory accesses into a consolidated access to consecutive DRAM locations.</p><blockquote><p><strong>Definition: Memory Coalescing</strong><br>If, in a warp, thread $0$ accesses location $n$, thread $1$ accesses location $n + 1$, &mldr; thread $31$ accesses location $n + 31$, then all these accesses are coalesced, that is: <strong>combined into one single access</strong>.</p></blockquote><p>The CUDA C Best Practices Guide gives a high priority recommendation to coalesced access to global memory.</p><h2 id=2-example-vector-addition>2. Example: Vector Addition<a hidden class=anchor aria-hidden=true href=#2-example-vector-addition>#</a></h2><h3 id=21-coalesced-access>2.1. Coalesced Access<a hidden class=anchor aria-hidden=true href=#21-coalesced-access>#</a></h3><p><strong>Coalesced Memory Access</strong> means that each thread in a warp accesses consecutive memory locations so that the hardware can combine all these accesses into one single access. By doing so, fewer wasted data are transferred and the memory bandwidth is fully utilized.</p><details class=custom-details><summary class=custom-summary>Click to See Example Code</summary><div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>vecAddKernel</span><span class=p>(</span><span class=k>const</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>a</span><span class=p>,</span> <span class=k>const</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>b</span><span class=p>,</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>c</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                             <span class=kt>int32_t</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>gtid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>gtid</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c1>// [DRAM] 2 load, 1 store, 3 inst
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>c</span><span class=p>[</span><span class=n>gtid</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>gtid</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>gtid</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>launchVecAdd</span><span class=p>(</span><span class=k>const</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>d_A</span><span class=p>,</span> <span class=k>const</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>d_B</span><span class=p>,</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>d_C</span><span class=p>,</span> <span class=n>size_t</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=n>dim3</span> <span class=n>blockSize</span> <span class=o>=</span> <span class=p>{</span><span class=n>std</span><span class=o>::</span><span class=n>min</span><span class=o>&lt;</span><span class=kt>uint32_t</span><span class=o>&gt;</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=mi>1024</span><span class=p>),</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>};</span>
</span></span><span class=line><span class=cl>    <span class=n>dim3</span> <span class=n>gridSize</span> <span class=o>=</span> <span class=p>{</span><span class=n>ceilDiv</span><span class=o>&lt;</span><span class=kt>uint32_t</span><span class=o>&gt;</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>blockSize</span><span class=p>.</span><span class=n>x</span><span class=p>),</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>};</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>vecAddKernel</span><span class=o>&lt;&lt;&lt;</span><span class=n>gridSize</span><span class=p>,</span> <span class=n>blockSize</span><span class=o>&gt;&gt;&gt;</span><span class=p>(</span><span class=n>d_A</span><span class=p>,</span> <span class=n>d_B</span><span class=p>,</span> <span class=n>d_C</span><span class=p>,</span> <span class=kt>int32_t</span><span class=p>(</span><span class=n>n</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></div></details><br><p>Note that in NVIDIA GPUs:</p><ul><li><strong>WARP</strong> is the smallest unit of execution, which contains 32 threads.</li><li><strong>SECTOR</strong> is the smallest unit of data that can be accessed from global memory, which is exactly 32 bytes.</li></ul><p>In the example above, all threads in a warp access consecutive memory locations both for <code>a</code>, <code>b</code>, and <code>c</code>, and for each $32 * 4 / 32 = 4$ sectors, only <strong>ONE</strong> instruction to a warp is needed to access the data. This is so-called <strong>coalesced memory access</strong>.</p><div class=image-container><img src="https://docs.google.com/drawings/d/e/2PACX-1vRXwpIJWOSYT4fXZ3ZwR8UZOXpqO0R_-AG5JLZQkm3BEZQ16KExQdAH58LkP1pvZbisQOI2-Gr0N1v_/pub?w=1006&amp;h=371" alt class=image width=100%><div class=image-caption>Coalesced Memory Access. There are 2N loads operations and 1N store operations in the kernel, which in all are 2N/32 load instructions and 1N/32 store instructions for warps (each warp executes 1 instruction). Since the access to memroy is coalesced, one instruction will transfer 4 sectors of data. There are no any wasted data.</div></div><p>Another example of coalesced memory access is shown below:</p><details class=custom-details><summary class=custom-summary>Click to See Example Code</summary><div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>vecAddKernelv1</span><span class=p>(</span><span class=k>const</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>a</span><span class=p>,</span> <span class=k>const</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>b</span><span class=p>,</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>c</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                               <span class=kt>int32_t</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>gtid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>gtid</span> <span class=o>=</span> <span class=n>gtid</span> <span class=o>%</span> <span class=mi>2</span> <span class=o>==</span> <span class=mi>0</span> <span class=o>?</span> <span class=n>gtid</span> <span class=o>+</span> <span class=mi>1</span> <span class=o>:</span> <span class=n>gtid</span> <span class=o>-</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>gtid</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c1>// [DRAM] 2 load, 1 store, 3 inst
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>c</span><span class=p>[</span><span class=n>gtid</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>gtid</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>gtid</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></div></details><br><p>Crompared to the previous example, each 2 threads exchange their access positions. However, the access to memory is still coalesced.</p><div class=image-container><img src="https://docs.google.com/drawings/d/e/2PACX-1vTGbAM6z2ZZwcftUcB4E80_PUqOMCr2Y6ErnGx5DCPqVqUqFaxlDV9IbcPHjUKI1PX7v6cwcZHWH2nT/pub?w=1006&amp;h=371" alt class=image width=100%><div class=image-caption>Another Example of Coalesced Memory Access. 1 intruction will transfer 4 sectors of data. There are no any wasted data.</div></div><h3 id=22-non-coalesced-access>2.2. Non-Coalesced Access<a hidden class=anchor aria-hidden=true href=#22-non-coalesced-access>#</a></h3><p><strong>Non-Coalesced Memory Access</strong> means that some thread in a warp accesses non-consecutive memory locations so that the hardware cannot combine all these accesses into one single access. By doing so, more wasted data are transferred and the memory bandwidth is not fully utilized.</p><p>See the example code below. Originally, 32 threads in a warp would access 32 consecutive fp32 elements. However, I make the first thread in each warp access the 33th fp32 element (which should be accessed by the next warp), making an intented non-coalesced access.</p><details class=custom-details><summary class=custom-summary>Click to See Example Code</summary><div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>__global__</span> <span class=kt>void</span> <span class=nf>vecAddKernelv1</span><span class=p>(</span><span class=k>const</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>a</span><span class=p>,</span> <span class=k>const</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>b</span><span class=p>,</span> <span class=n>fp32_t</span><span class=o>*</span> <span class=n>c</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                               <span class=kt>int32_t</span> <span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>int</span> <span class=n>gtid</span> <span class=o>=</span> <span class=n>threadIdx</span><span class=p>.</span><span class=n>x</span> <span class=o>+</span> <span class=n>blockDim</span><span class=p>.</span><span class=n>x</span> <span class=o>*</span> <span class=n>blockIdx</span><span class=p>.</span><span class=n>x</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>gtid</span> <span class=o>%</span> <span class=n>warpSize</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>gtid</span> <span class=o>=</span> <span class=p>(</span><span class=n>gtid</span> <span class=o>+</span> <span class=n>warpSize</span><span class=p>)</span> <span class=o>%</span> <span class=p>(</span><span class=n>ceilDiv</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=n>warpSize</span><span class=p>)</span> <span class=o>*</span> <span class=n>warpSize</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>gtid</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c1>// [DRAM] 2 load, 1 store, 3 inst
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>c</span><span class=p>[</span><span class=n>gtid</span><span class=p>]</span> <span class=o>=</span> <span class=n>a</span><span class=p>[</span><span class=n>gtid</span><span class=p>]</span> <span class=o>+</span> <span class=n>b</span><span class=p>[</span><span class=n>gtid</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></div></details><br><p>The memory access pattern is shown in the figure below. Campare to the previous examples, you can see that despite the total number of load/store instructions is the same (2N/32 load instructions and 1N/32 store instructions), for each warp, 5 sectors of data are now being transferred per instruction. From the perspective of hardware, more data are being transferred than needed.</p><div class=image-container><img src="https://docs.google.com/drawings/d/e/2PACX-1vS26Ml2jmtIYgk4jhrnmAihGKhuGMcjnwM3aqh784REEtZVLh2_fEva6GbyaroJ9ZrF-w1QmRONlxQm/pub?w=1006&amp;h=371" alt class=image width=100%><div class=image-caption>Non-Coalesced Memory Access. There are 2N/32 load instructions and 1N/32 store instructions for warps. But one instruction will transfer 5 sectors of data, as shown in the first warp with 5 orange sectors.</div></div><p>In Nsight Compute, you can see the performance analysis in the &ldquo;Memory Workload Analysis&rdquo; section. Optimization suggestions are provided for reducing wasted data transfer.</p><div class=image-container><img src=/imgs/blogs/cuda-programming-notes-01-memory-coalescing/non-coalesced-nsight-compute.png alt class=image width=100%><div class=image-caption>Performance analysis of non-coalesced memory access using Nsight Compute.</div></div><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ol><li><a href=https://www.elsevier.com/books/programming-massively-parallel-processors/kirk/978-0-12-811986-0 target=_blank rel="noopener noreferrer">Programming Massively Parallel Processors: A Hands-on Approach, 4th Edition</a></li><li><a href=https://www.bilibili.com/video/BV1NYCtYTEFH target=_blank rel="noopener noreferrer">【CUDA调优指南】合并访存</a></li><li><a href=https://homepages.math.uic.edu/~jan/mcs572/memory_coalescing.pdf target=_blank rel="noopener noreferrer">Memory Coalescing Techniques</a></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://jamesnulliu.github.io/tags/cuda/>Cuda</a></li><li><a href=https://jamesnulliu.github.io/tags/optimization/>Optimization</a></li></ul><nav class=paginav><a class=prev href=https://jamesnulliu.github.io/blogs/reinforcement-learning-for-llms/><span class=title>« Prev</span><br><span>Reinforcement Learning for LLMs</span>
</a><a class=next href=https://jamesnulliu.github.io/blogs/arithmetic-intensity-estimation-of-large-language-models/><span class=title>Next »</span><br><span>Arithmetic Intensity Estimation of Large Language Models</span></a></nav></footer><script src=https://giscus.app/client.js data-repo=jamesnulliu/jamesnulliu.github.io data-repo-id=R_kgDOMPCQIw data-category=Announcements data-category-id=DIC_kwDOMPCQI84Cgb2t data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en crossorigin=anonymous async></script></article></main><footer class=footer><span>© 2024-2025 JamesNULLiu</span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
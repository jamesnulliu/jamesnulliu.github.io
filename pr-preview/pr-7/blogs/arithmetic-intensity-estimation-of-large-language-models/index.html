<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Arithmetic Intensity Estimation of Large Language Models | 秋水·JamesNULLiu</title><meta name=keywords content="speculative decoding"><meta name=description content="This blog post discusses the arithmetic intensity of large language models and how it affects the performance of these models."><meta name=author content="jamesnulliu"><link rel=canonical href=https://jamesnulliu.github.io/blogs/arithmetic-intensity-estimation-of-large-language-models/><link crossorigin=anonymous href=/assets/css/stylesheet.62cb9c488bb33c0e9a9d3c29b7f4259cbb0db25aaa19ba672188203d3d5bcaf9.css integrity="sha256-YsucSIuzPA6anTwpt/QlnLsNslqqGbpnIYggPT1byvk=" rel="preload stylesheet" as=style><link rel=icon href=https://jamesnulliu.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://jamesnulliu.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://jamesnulliu.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://jamesnulliu.github.io/apple-touch-icon.png><link rel=mask-icon href=https://jamesnulliu.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://jamesnulliu.github.io/blogs/arithmetic-intensity-estimation-of-large-language-models/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>MathJax={tex:{displayMath:[["\\[","\\]"],["$$","$$"]],inlineMath:[["\\(","\\)"],["$","$"]]}}</script><meta property="og:url" content="https://jamesnulliu.github.io/blogs/arithmetic-intensity-estimation-of-large-language-models/"><meta property="og:site_name" content="秋水·JamesNULLiu"><meta property="og:title" content="Arithmetic Intensity Estimation of Large Language Models"><meta property="og:description" content="This blog post discusses the arithmetic intensity of large language models and how it affects the performance of these models."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2025-03-13T17:38:00+08:00"><meta property="article:modified_time" content="2025-09-12T16:00:18-07:00"><meta property="article:tag" content="Transformer"><meta property="article:tag" content="Llm"><meta property="article:tag" content="Vllm"><meta name=twitter:card content="summary"><meta name=twitter:title content="Arithmetic Intensity Estimation of Large Language Models"><meta name=twitter:description content="This blog post discusses the arithmetic intensity of large language models and how it affects the performance of these models."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://jamesnulliu.github.io/blogs/"},{"@type":"ListItem","position":2,"name":"Arithmetic Intensity Estimation of Large Language Models","item":"https://jamesnulliu.github.io/blogs/arithmetic-intensity-estimation-of-large-language-models/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Arithmetic Intensity Estimation of Large Language Models","name":"Arithmetic Intensity Estimation of Large Language Models","description":"This blog post discusses the arithmetic intensity of large language models and how it affects the performance of these models.","keywords":["speculative decoding"],"articleBody":"1. Estimating Total FLOPs We only consider the FLOPs of Transformer layers, excluding the embedding layer and the output layer.\nAttention:\nEach projection for Q, K and V is matmul of input (B, S, H) and weight (H, H), yielding (B, S, H):\n$$ \\text{FLOPs} = 3 \\times (2 \\times B \\times S \\times H \\times H) = 6 \\times B \\times S \\times H^2 $$ $S = QK^T$, matmul of $Q$ (B, S, H) and $K^T$ (B, H, S), yielding (B, S, S):\n$$ \\text{FLOPs} = 2 \\times B \\times S \\times S \\times H = 2 \\times B \\times S^2 \\times H $$ $L = S \\cdot V$, matmul of $S$ (B, S, S) and $V$ (B, S, H), yielding (B, S, H):\n$$ \\text{FLOPs} = 2 \\times B \\times S \\times H \\times S $$ $O = L \\cdot W_O$, matmul of $L$ (B, S, H) and $W_O$ (H, H), yielding (B, S, H):\n$$ \\text{FLOPs} = 2 \\times B \\times S \\times H^2 $$ Total attention FLOPs per Transformer layer: $$ \\text{FLOPs} = 8 \\times B \\times S \\times H^2 + 4 \\times B \\times S^2 \\times H $$ Feed-Forward Networek\nTypically 2 linear layers, one mapping (B, S, H) to (B, S, 4H) and the other mapping (B, S, 4H) to (B, S, H):\nTotal FFN FLOPs per Transformer layer:\n$$ \\begin{align*} \\text{FLOPs} \u0026= 2 \\times B \\times S \\times H \\times (4 \\times H) + 2 \\times B \\times S \\times (4 \\times H) \\times H \\\\ \u0026= 16 \\times B \\times S \\times H^2 \\end{align*} $$ Total FLOPs: $N$ Layers of Transformer\nEach Transformer layer consists of an attention mechanism and a feed-forward network\nWhen prefilling, the total FLOPs is:\n$$ \\text{FLOPs}_\\text{total} = N (24 B S H^2 + 4 B S^2 H) $$ When decoding, suppose the input is of shape (B, Si, H) and KV cache is of shape (B, Sc, H), the total FLOPs is:\n$$ \\text{FLOPs}_\\text{total} = N (24 B S_i H^2 + 4 B S_i S_c H) $$ 2. Estimating Total Bytes Transfered In FP16, each parameter or activation element is 2 bytes.\nData transferred includes loading model weights and handling activations.\nSuppose we have a $Z$-B-fp16 model and $N$ Transformer layers, each with input size (B, S, H).\nModel Weights\nA $Z$-B-fp16 model has $Z \\times 10^9$ fp16 parameters, each 2 bytes:\n$$ \\text{Bytes}_\\text{weights} = Z \\times 10^9 \\times 2 ~ \\text{Bytes} = 2 \\times Z ~ \\text{GBytes} $$In an optimized GPU inference, weights are typically loaded into high-bandwidth memory (HBM) once and reused, so we assume $2Z$ GB is read once per forward pass.\nActivations\nFor each Transfomer layer, input and output activations are of shape (B, S, H), and each element is 2 bytes in fp16: $$ \\text{Bytes}_\\text{act-layer} = B \\times S \\times H \\times 2 ~ \\text{Bytes} $$ For $N$ layers, activations are computed sequentially. Since each layer’s output becomes the next layer’s input (read once, written once):\n$$ \\begin{align*} \\text{Bytes}_\\text{act-total} \u0026= 2 \\times N \\times \\text{Bytes}_\\text{act-layer} ~ \\text{Bytes} \\\\ \u0026= 4 \\times N \\times B \\times S \\times H ~ \\text{Bytes} \\end{align*} $$ KV Caches\nWhen decoding, each Transformer layer would load cached K and V both of shape (B, Sc, H). After decoding, the new K and V of shape (B, Si, H) are computed and cached for the next layer. So the bytes transfered for one forward pass is:\n$$ \\text{Bytes}_\\text{KV} = N \\times (B \\times S_c \\times H + 2 \\times B \\times S_i \\times H) \\times 2 ~ \\text{Bytes} $$ Total Data Transferred\nWhen prefilling, the total bytes transferred is:\n$$ \\begin{align*} \\text{Bytes}_\\text{total} \u0026= \\text{Bytes}_\\text{weights} + \\text{Bytes}_\\text{act-total} \\\\ \u0026= 2 Z \\text{e}^9 + 4 N B S H ~ \\text{Bytes} \\end{align*} $$ When decoding, suppose cached sequence length is $S_c$ and the input sequence length is $S_i$, the total bytes transferred is:\n$$ \\begin{align*} \\text{Bytes}_\\text{total} \u0026= \\text{Bytes}_\\text{weights} + \\text{Bytes}_\\text{act-total} + \\text{Bytes}_\\text{KV} \\\\ \u0026= 2 Z \\text{e}^{9} + 8 N B S_i H + 2 N B S_c H ~ \\text{Bytes} \\end{align*} $$ 3. Arithmetic Intensity When prefilling, there is no cached K and V, so the arithmetic intensity is:\n$$ \\begin{align*} \\text{Arithmetic Intensity} \u0026= \\text{FLOPs}_\\text{total} / \\text{Bytes}_\\text{total} \\\\ \u0026= \\frac{N (24 B S H^2 + 4 B S^2 H)}{2 Z 10^9 + 4 N B S H} \\end{align*} $$When decoding, suppose cached sequence length is $S_c$ and the input sequence length is $S_i$ , then the arithmetic intensity is:\n$$ \\begin{align*} \\text{Arithmetic Intensity} \u0026= \\text{FLOPs}_\\text{total} / \\text{Bytes}_\\text{total} \\\\ \u0026= \\frac{N (24 B S_i H^2 + 4 B S_i S_c H)}{2 Z 10^9 + 8 N B S_i H + 2 N B S_c H} \\end{align*} $$4. Roofline Model Roofline Model. If the arithmetic intensity is on the right side of the machine balance, the performance compute-bound. If it is on the left side, the performance is memory-bound. A100-80GB has the following hardware `specifications:\nPeak FLOPs ($\\pi$): $312 \\times 10^{12}$ FLOPs/s Memory Bandwidth ($\\beta$): $2039 \\times 10^9$ B/s Machine Balance ($I_{max}$): $312 \\times 10^{12} / (2039 \\times 10^9) \\approx 153$ FLOPs/Byte Here are two examples of arithmetic intensity estimation:\nSee: Arithmetic Intensity for Prefilling See: Arithmetic Intensity for Speculative Decoding 5. Discussion: Tensor Parallelism If the model is split across multiple GPUs using TP, the hidden size H and the model weight is divided by the number of GPUs.\n","wordCount":"889","inLanguage":"en","datePublished":"2025-03-13T17:38:00+08:00","dateModified":"2025-09-12T16:00:18-07:00","author":[{"@type":"Person","name":"jamesnulliu"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://jamesnulliu.github.io/blogs/arithmetic-intensity-estimation-of-large-language-models/"},"publisher":{"@type":"Organization","name":"秋水·JamesNULLiu","logo":{"@type":"ImageObject","url":"https://jamesnulliu.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://jamesnulliu.github.io/ accesskey=h title="秋水·JamesNULLiu (Alt + H)">秋水·JamesNULLiu</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://jamesnulliu.github.io/zh/ title=简体中文 aria-label=简体中文>简体中文</a></li></ul></div></div><ul id=menu><li><a href=https://jamesnulliu.github.io/ title=Home><span>Home</span></a></li><li><a href=https://jamesnulliu.github.io/about_me/ title="About Me"><span>About Me</span></a></li><li><a href=https://jamesnulliu.github.io/blogs/ title=Blogs><span>Blogs</span></a></li><li><a href=https://jamesnulliu.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://jamesnulliu.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://jamesnulliu.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://jamesnulliu.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://jamesnulliu.github.io/friends/ title=Friends><span>Friends</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://jamesnulliu.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://jamesnulliu.github.io/blogs/>Blogs</a></div><h1 class="post-title entry-hint-parent">Arithmetic Intensity Estimation of Large Language Models</h1><div class=post-description>This blog post discusses the arithmetic intensity of large language models and how it affects the performance of these models.</div><div class=post-meta><span title='2025-03-13 17:38:00 +0800 +0800'>Mar-13-2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;889 words&nbsp;·&nbsp;jamesnulliu</div></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-estimating-total-flops aria-label="1. Estimating Total FLOPs">1. Estimating Total FLOPs</a></li><li><a href=#2-estimating-total-bytes-transfered aria-label="2. Estimating Total Bytes Transfered">2. Estimating Total Bytes Transfered</a></li><li><a href=#3-arithmetic-intensity aria-label="3. Arithmetic Intensity">3. Arithmetic Intensity</a></li><li><a href=#4-roofline-model aria-label="4. Roofline Model">4. Roofline Model</a></li><li><a href=#5-discussion-tensor-parallelism aria-label="5. Discussion: Tensor Parallelism">5. Discussion: Tensor Parallelism</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{let e=null;const t=window.innerHeight+window.pageYOffset>=document.body.offsetHeight-100;if(t)e=elements[elements.length-1];else{let t=null,n=1/0;elements.forEach(e=>{const s=getOffsetTop(e)-window.pageYOffset;if(s<=window.innerHeight*.3){const o=Math.abs(s);o<n&&(n=o,t=e)}}),e=t||elements[0]}if(e&&e!==activeElement){if(activeElement){const t=encodeURI(activeElement.getAttribute("id")).toLowerCase(),e=document.querySelector(`.inner ul li a[href="#${t}"]`);e&&e.classList.remove("active")}activeElement=e;const n=encodeURI(activeElement.getAttribute("id")).toLowerCase(),t=document.querySelector(`.inner ul li a[href="#${n}"]`);t&&(t.classList.add("active"),document.getElementById("toc-container").classList.contains("wide")&&scrollTocToActiveItem(t))}},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}function scrollTocToActiveItem(e){const t=document.querySelector(".toc .inner");if(!t||!e)return;const n=t.getBoundingClientRect(),s=e.getBoundingClientRect(),o=n.height/2,i=s.top-n.top+t.scrollTop,a=i-o;t.scrollTo({top:Math.max(0,a),behavior:"smooth"})}</script><div class=post-content><h2 id=1-estimating-total-flops>1. Estimating Total FLOPs<a hidden class=anchor aria-hidden=true href=#1-estimating-total-flops>#</a></h2><p>We only consider the FLOPs of Transformer layers, excluding the embedding layer and the output layer.</p><ul><li><p><strong>Attention</strong>:</p><ol><li>Each projection for Q, K and V is matmul of input <code>(B, S, H)</code> and weight <code>(H, H)</code>, yielding <code>(B, S, H)</code>:<br>$$
\text{FLOPs} = 3 \times (2 \times B \times S \times H \times H) = 6 \times B \times S \times H^2
$$</li><li>$S = QK^T$, matmul of $Q$ <code>(B, S, H)</code> and $K^T$ <code>(B, H, S)</code>, yielding <code>(B, S, S)</code>:<br>$$
\text{FLOPs} = 2 \times B \times S \times S \times H = 2 \times B \times S^2 \times H
$$</li><li>$L = S \cdot V$, matmul of $S$ <code>(B, S, S)</code> and $V$ <code>(B, S, H)</code>, yielding <code>(B, S, H)</code>:<br>$$
\text{FLOPs} = 2 \times B \times S \times H \times S
$$</li><li>$O = L \cdot W_O$, matmul of $L$ <code>(B, S, H)</code> and $W_O$ <code>(H, H)</code>, yielding <code>(B, S, H)</code>:<br>$$
\text{FLOPs} = 2 \times B \times S \times H^2
$$</li><li>Total attention FLOPs per Transformer layer:
$$
\text{FLOPs} = 8 \times B \times S \times H^2 + 4 \times B \times S^2 \times H
$$</li></ol></li><li><p><strong>Feed-Forward Networek</strong><br>Typically 2 linear layers, one mapping <code>(B, S, H)</code> to <code>(B, S, 4H)</code> and the other mapping <code>(B, S, 4H)</code> to <code>(B, S, H)</code>:</p><ul><li><p>Total FFN FLOPs per Transformer layer:</p>$$
\begin{align*}
\text{FLOPs} &= 2 \times B \times S \times H \times (4 \times H) + 2 \times B \times S \times (4 \times H) \times H \\
&= 16 \times B \times S \times H^2
\end{align*}
$$</li></ul></li><li><p><strong>Total FLOPs: $N$ Layers of Transformer</strong><br>Each Transformer layer consists of an attention mechanism and a feed-forward network</p><ul><li><p>When prefilling, the total FLOPs is:</p>$$
\text{FLOPs}_\text{total} = N (24 B S H^2 + 4 B S^2 H)
$$</li><li><p>When decoding, suppose the input is of shape <code>(B, Si, H)</code> and KV cache is of shape <code>(B, Sc, H)</code>, the total FLOPs is:</p>$$
\text{FLOPs}_\text{total} = N (24 B S_i H^2 + 4 B S_i S_c H)
$$</li></ul></li></ul><h2 id=2-estimating-total-bytes-transfered>2. Estimating Total Bytes Transfered<a hidden class=anchor aria-hidden=true href=#2-estimating-total-bytes-transfered>#</a></h2><p>In FP16, each parameter or activation element is 2 bytes.</p><p>Data transferred includes <strong>loading model weights</strong> and <strong>handling activations</strong>.</p><p>Suppose we have a $Z$-B-fp16 model and $N$ Transformer layers, each with input size <code>(B, S, H)</code>.</p><ul><li><p><strong>Model Weights</strong><br>A $Z$-B-fp16 model has $Z \times 10^9$ <code>fp16</code> parameters, each 2 bytes:</p>$$
\text{Bytes}_\text{weights} = Z \times 10^9 \times 2 ~ \text{Bytes} = 2 \times Z ~ \text{GBytes}
$$<p>In an optimized GPU inference, weights are typically loaded into high-bandwidth memory (HBM) once and reused, so we assume $2Z$ GB is read once per forward pass.</p></li><li><p><strong>Activations</strong></p><ul><li>For each Transfomer layer, input and output activations are of shape <code>(B, S, H)</code>, and each element is 2 bytes in <code>fp16</code>:
$$
\text{Bytes}_\text{act-layer} = B \times S \times H \times 2 ~ \text{Bytes}
$$</li><li>For $N$ layers, activations are computed sequentially. Since each layer’s output becomes the next layer’s input (read once, written once):<br>$$
\begin{align*}
\text{Bytes}_\text{act-total} &= 2 \times N \times \text{Bytes}_\text{act-layer} ~ \text{Bytes} \\
&= 4 \times N \times B \times S \times H ~ \text{Bytes}
\end{align*}
$$</li></ul></li><li><p><strong>KV Caches</strong><br>When decoding, each Transformer layer would load cached K and V both of shape <code>(B, Sc, H)</code>. After decoding, the new K and V of shape <code>(B, Si, H)</code> are computed and cached for the next layer. So the bytes transfered for one forward pass is:</p>$$
\text{Bytes}_\text{KV} = N \times (B \times S_c \times H + 2 \times B \times S_i \times H) \times 2 ~ \text{Bytes}
$$</li><li><p><strong>Total Data Transferred</strong></p><ul><li><p>When prefilling, the total bytes transferred is:</p>$$
\begin{align*}
\text{Bytes}_\text{total} &= \text{Bytes}_\text{weights} + \text{Bytes}_\text{act-total} \\
&= 2 Z \text{e}^9 + 4 N B S H ~ \text{Bytes}
\end{align*}
$$</li><li><p>When decoding, suppose cached sequence length is $S_c$ and the input sequence length is $S_i$, the total bytes transferred is:</p>$$
\begin{align*}
\text{Bytes}_\text{total} &= \text{Bytes}_\text{weights} + \text{Bytes}_\text{act-total} + \text{Bytes}_\text{KV} \\
&= 2 Z \text{e}^{9} + 8 N B S_i H + 2 N B S_c H ~ \text{Bytes}
\end{align*}
$$</li></ul></li></ul><h2 id=3-arithmetic-intensity>3. Arithmetic Intensity<a hidden class=anchor aria-hidden=true href=#3-arithmetic-intensity>#</a></h2><p>When prefilling, there is no cached K and V, so the arithmetic intensity is:</p>$$
\begin{align*}
\text{Arithmetic Intensity} &= \text{FLOPs}_\text{total} / \text{Bytes}_\text{total} \\
&= \frac{N (24 B S H^2 + 4 B S^2 H)}{2 Z 10^9 + 4 N B S H}
\end{align*}
$$<p>When decoding, suppose cached sequence length is $S_c$ and the input sequence length is $S_i$ , then the arithmetic intensity is:</p>$$
\begin{align*}
\text{Arithmetic Intensity} &= \text{FLOPs}_\text{total} / \text{Bytes}_\text{total} \\
&= \frac{N (24 B S_i H^2 + 4 B S_i S_c H)}{2 Z 10^9 + 8 N B S_i H + 2 N B S_c H}
\end{align*}
$$<h2 id=4-roofline-model>4. Roofline Model<a hidden class=anchor aria-hidden=true href=#4-roofline-model>#</a></h2><div class=image-container><img src=/imgs/blogs/arithmetic-intensity-estimation-of-large-language-models/roofline_model.png alt class=image width=80%><div class=image-caption>Roofline Model. If the arithmetic intensity is on the right side of the machine balance, the performance compute-bound. If it is on the left side, the performance is memory-bound.</div></div><p>A100-80GB has the following hardware `specifications:</p><ul><li><strong>Peak FLOPs</strong> ($\pi$): $312 \times 10^{12}$ FLOPs/s</li><li><strong>Memory Bandwidth</strong> ($\beta$): $2039 \times 10^9$ B/s</li><li><strong>Machine Balance</strong> ($I_{max}$): $312 \times 10^{12} / (2039 \times 10^9) \approx 153$ FLOPs/Byte</li></ul><p>Here are two examples of arithmetic intensity estimation:</p><ul><li>See: <a href=https://www.geogebra.org/calculator/uqzhngtf target=_blank rel="noopener noreferrer">Arithmetic Intensity for Prefilling</a></li><li>See: <a href=https://www.geogebra.org/calculator/tkkekjdb target=_blank rel="noopener noreferrer">Arithmetic Intensity for Speculative Decoding</a></li></ul><h2 id=5-discussion-tensor-parallelism>5. Discussion: Tensor Parallelism<a hidden class=anchor aria-hidden=true href=#5-discussion-tensor-parallelism>#</a></h2><p>If the model is split across multiple GPUs using TP, the hidden size <code>H</code> and the model weight is divided by the number of GPUs.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://jamesnulliu.github.io/tags/transformer/>Transformer</a></li><li><a href=https://jamesnulliu.github.io/tags/llm/>Llm</a></li><li><a href=https://jamesnulliu.github.io/tags/vllm/>Vllm</a></li></ul><nav class=paginav><a class=prev href=https://jamesnulliu.github.io/blogs/cuda-programming-notes-01-memory-coalescing/><span class=title>« Prev</span><br><span>CUDA Programming Notes | 01: Memory Coalescing</span>
</a><a class=next href=https://jamesnulliu.github.io/blogs/a-brief-talk-on-speculative-decoding/><span class=title>Next »</span><br><span>A Brief Talk on Speculative Decoding</span></a></nav></footer><script src=https://giscus.app/client.js data-repo=jamesnulliu/jamesnulliu.github.io data-repo-id=R_kgDOMPCQIw data-category=Announcements data-category-id=DIC_kwDOMPCQI84Cgb2t data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en crossorigin=anonymous async></script></article></main><footer class=footer><span>© 2024-2025 JamesNULLiu</span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>